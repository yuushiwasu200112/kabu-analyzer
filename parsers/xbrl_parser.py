"""
XBRLãƒ‘ãƒ¼ã‚µãƒ¼ - IFRS/æ—¥æœ¬åŸºæº–å¯¾å¿œãƒ»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé™¤å¤–ç‰ˆ
"""
import requests, zipfile, io
from lxml import etree

TAG_GROUPS = {
    "å£²ä¸Šé«˜": [
        "SalesAndFinancialServicesRevenueIFRS",
        "TotalNetRevenuesIFRS",
        "RevenueIFRS",
        "NetSalesIFRS",
        "NetSalesSummaryOfBusinessResults",
        "NetSales",
        "Revenue",
    ],
    "å–¶æ¥­åˆ©ç›Š": [
        "OperatingProfitLossIFRS",
        "OperatingIncome",
    ],
    "ç´”åˆ©ç›Š": [
        "ProfitLossAttributableToOwnersOfParentIFRS",
        "ProfitLossAttributableToOwnersOfParent",
        "NetIncomeLossSummaryOfBusinessResults",
        "NetIncome",
    ],
    "ç·è³‡ç”£": [
        "AssetsIFRS",
        "TotalAssetsIFRSSummaryOfBusinessResults",
        "TotalAssets",
        "Assets",
    ],
    "è‡ªå·±è³‡æœ¬": [
        "EquityAttributableToOwnersOfParentIFRS",
        "ShareholdersEquity",
    ],
    "ç´”è³‡ç”£": ["EquityIFRS", "NetAssets"],
    "æµå‹•è³‡ç”£": ["CurrentAssetsIFRS", "CurrentAssets"],
    "æµå‹•è² å‚µ": ["CurrentLiabilitiesIFRS", "CurrentLiabilities"],
    "æ”¯æ‰•åˆ©æ¯": ["InterestExpensesNOE", "InterestExpense", "FinanceCosts"],
    "å–¶æ¥­CF": [
        "NetCashProvidedByUsedInOperatingActivitiesIFRS",
        "CashFlowsFromOperatingActivities",
    ],
    "1æ ªé…å½“": ["DividendPaidPerShareSummaryOfBusinessResults", "DividendPerShare"],
    "ç™ºè¡Œæ¸ˆæ ªå¼æ•°": [
        "TotalNumberOfIssuedSharesSummaryOfBusinessResults",
        "NumberOfIssuedSharesAsOfFiscalYearEndIssuedSharesTotalNumberOfSharesEtc",
    ],
    "æœ‰åˆ©å­è² å‚µ_çŸ­æœŸ": ["InterestBearingLiabilitiesCLIFRS"],
    "æœ‰åˆ©å­è² å‚µ_é•·æœŸ": ["InterestBearingLiabilitiesNCLIFRS"],
    "æœ‰åˆ©å­è² å‚µ": ["InterestBearingDebt"],
}


def _is_current_consolidated(context_ref):
    """å½“æœŸã®é€£çµå…¨ä½“ãƒ‡ãƒ¼ã‚¿ã‹ã©ã†ã‹åˆ¤å®š"""
    if not context_ref:
        return False
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
    segment_keywords = [
        "_jpcrp030000", "Segment", "Game", "Music", "Picture",
        "Enter", "Imag", "Finan", "Reportable",
        "NonConsolidated", "Elimination",
    ]
    for kw in segment_keywords:
        if kw in context_ref:
            return False
    # å‰æœŸã‚’é™¤å¤–
    if "Prior" in context_ref:
        return False
    # å½“æœŸã®é€£çµ
    if "CurrentYear" in context_ref:
        return True
    if "Current" in context_ref:
        return True
    return False


def _is_current_any(context_ref):
    """å½“æœŸãƒ‡ãƒ¼ã‚¿ã‹ã©ã†ã‹ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚‚å«ã‚€åºƒã„åˆ¤å®šï¼‰"""
    if not context_ref:
        return False
    if "Prior" in context_ref:
        return False
    return True


def download_and_parse(doc_id, api_key):
    resp = requests.get(
        f"https://api.edinet-fsa.go.jp/api/v2/documents/{doc_id}",
        params={"type": 1, "Subscription-Key": api_key},
        timeout=60,
    )
    if resp.status_code != 200:
        return None
    try:
        with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:
            xbrl_files = [n for n in zf.namelist() if n.endswith(".xbrl")]
            if not xbrl_files:
                return None
            main_xbrl = max(xbrl_files, key=lambda n: len(zf.read(n)))
            xml_data = zf.read(main_xbrl)
    except zipfile.BadZipFile:
        return None
    return parse_xbrl(xml_data)


def extract_xbrl_from_zip(zip_data):
    """ZIPã‹ã‚‰XBRLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º"""
    try:
        z = zipfile.ZipFile(io.BytesIO(zip_data))
        for name in z.namelist():
            if name.endswith('.xbrl') and 'XBRL/PublicDoc/' in name:
                return z.read(name)
        # PublicDocãŒãªã„å ´åˆ
        for name in z.namelist():
            if name.endswith('.xbrl'):
                return z.read(name)
    except:
        pass
    return None


def parse_xbrl(xml_data):
    # ZIPã®å ´åˆã¯å±•é–‹
    if xml_data[:2] == b'PK':
        xml_data = extract_xbrl_from_zip(xml_data)
        if not xml_data:
            return None
    root = etree.fromstring(xml_data)

    # å…¨ã‚¿ã‚°ã‚’åé›†ï¼ˆcontextRefä»˜ãï¼‰
    all_entries = {}
    for elem in root.iter():
        tag = elem.tag.split("}")[-1] if "}" in elem.tag else elem.tag
        ctx = elem.get("contextRef", "")
        if elem.text:
            try:
                val = float(elem.text.replace(",", ""))
                if tag not in all_entries:
                    all_entries[tag] = []
                all_entries[tag].append({"value": val, "context": ctx})
            except ValueError:
                pass

    def get_current_consolidated(tag_name):
        """å½“æœŸã®é€£çµå…¨ä½“ã®å€¤ã‚’å–å¾—"""
        entries = all_entries.get(tag_name, [])
        if not entries:
            return None

        # ã¾ãšå½“æœŸé€£çµã§ãƒ•ã‚£ãƒ«ã‚¿
        current = [e for e in entries if _is_current_consolidated(e["context"])]
        if current:
            # é€£çµå…¨ä½“ã¯é€šå¸¸æœ€å¤§å€¤ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆè¨ˆ > å€‹åˆ¥ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼‰
            return max(current, key=lambda e: abs(e["value"]))["value"]

        # å½“æœŸé€£çµãŒè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ã€å½“æœŸã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰
        current_any = [e for e in entries if _is_current_any(e["context"])]
        if current_any:
            return max(current_any, key=lambda e: abs(e["value"]))["value"]

        # ãã‚Œã§ã‚‚ãªã‘ã‚Œã°å…¨ä½“ã‹ã‚‰æœ€å¤§å€¤
        return max(entries, key=lambda e: abs(e["value"]))["value"]

    # å„ªå…ˆåº¦é †ã§ãƒãƒƒãƒãƒ³ã‚°
    results = {}
    for label, tag_list in TAG_GROUPS.items():
        for tag_name in tag_list:
            val = get_current_consolidated(tag_name)
            if val is not None:
                results[label] = val
                break

    # æœ‰åˆ©å­è² å‚µ = çŸ­æœŸ + é•·æœŸ
    if "æœ‰åˆ©å­è² å‚µ_çŸ­æœŸ" in results or "æœ‰åˆ©å­è² å‚µ_é•·æœŸ" in results:
        short = results.pop("æœ‰åˆ©å­è² å‚µ_çŸ­æœŸ", 0)
        long_d = results.pop("æœ‰åˆ©å­è² å‚µ_é•·æœŸ", 0)
        if "æœ‰åˆ©å­è² å‚µ" not in results:
            results["æœ‰åˆ©å­è² å‚µ"] = short + long_d
    results.pop("æœ‰åˆ©å­è² å‚µ_çŸ­æœŸ", None)
    results.pop("æœ‰åˆ©å­è² å‚µ_é•·æœŸ", None)

    # è‡ªå·±è³‡æœ¬ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if "è‡ªå·±è³‡æœ¬" not in results and "ç´”è³‡ç”£" in results:
        results["è‡ªå·±è³‡æœ¬"] = results["ç´”è³‡ç”£"]

    # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    if results.get("è‡ªå·±è³‡æœ¬", 0) > results.get("ç·è³‡ç”£", float("inf")):
        if "ç´”è³‡ç”£" in results:
            results["è‡ªå·±è³‡æœ¬"] = results["ç´”è³‡ç”£"]

    return results


def fetch_multi_year(doc_list, api_key):
    all_data = {}
    for doc in doc_list:
        doc_id = doc["docID"]
        period_end = doc.get("periodEnd", "ä¸æ˜")
        desc = doc.get("docDescription", "")
        print(f"  ğŸ“¥ {desc} ã‚’å‡¦ç†ä¸­...")
        data = download_and_parse(doc_id, api_key)
        if data:
            all_data[period_end] = data
            print(f"     âœ… {len(data)} é …ç›®å–å¾—")
        else:
            print(f"     âŒ å–å¾—å¤±æ•—")
    return all_data
